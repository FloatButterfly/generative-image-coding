<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Generative Image Coding with Diffusion Prior - ICME 2025">
  <title>Generative Image Coding with Diffusion Prior</title>
  <link rel="stylesheet" href="css/style.css">
</head>
<body>
  <header>
    <h1>Generative Image Coding with Diffusion Prior</h1>
    <h3>ICME 2025</h3>
    <p>Jianhui Chang, China Telecom Cloud Computing Research Institute</p>
    <nav>
      <a href="static/papers/372.pdf">[Paper PDF]</a>
      <a href="static/papers/ICME_supplementary.pdf">[Supplementary]</a>
      <!-- <a href="https://github.com/yourusername/generative-image-coding">[Code]</a> -->
    </nav>
    <p style="font-size: 0.9em; margin-top: 0.5em;">Camera-ready version for presentation only. Not the final published PDF.</p>
  </header>

  <main class="container">
    <section>
      <h2>üîç TL;DR</h2>
      <p>
        We propose a generative image coding framework that leverages pretrained diffusion models to achieve high perceptual quality at extremely low bitrates. The method achieves up to <strong>79% bitrate savings over VVC</strong> and generalizes well across both AI-generated and natural content.
      </p>
    </section>

    <section>
      <h2>üéØ Key Contributions</h2>
      <ul>
        <li>Propose a novel diffusion-prior-based image compression framework</li>
        <li>Design a lightweight adapter and attentive fusion module for high-fidelity decoding</li>
        <li>Introduce a color distribution renormalization technique for fidelity enhancement</li>
        <li>Enable flexible adaptation to multiple pretrained diffusion models</li>
        <li>Demonstrate superior performance on AIGC and natural image datasets</li>
      </ul>
    </section>

    <section>
      <h2>üì∑ Method Overview</h2>
      <img src="images/main_frame2.png" alt="Framework Diagram" class="responsive">
      <p>
        The image encoder and entropy model produce compressed latents, which are transformed by a lightweight adapter and fused with U-Net features in a latent diffusion model to guide high-fidelity image reconstruction.
      </p>
    </section>

    <section>
        <h2>üìä Results</h2>
        <p><strong>R-D Curve</strong> on AIGC Dataset (DiffusionDB):</p>
        <img src="static/images/AIGC_RD.png" alt="AIGC RD Curve" class="responsive">
  
        <p><strong>R-D Curve</strong> on Kodak Dataset (Natural Images):</p>
        <img src="static/images/kodak_RD.png" alt="Kodak RD Curve" class="responsive">
  
      <p><strong>Qualitative Comparison</strong> (zoom for details):</p>
      <img src="static/images/sub_comp.png" alt="Visual Comparison" class="responsive">
    </section>

    <section>
      <h2>üìö Citation</h2>
      <pre>
@inproceedings{chang2025generative,
  title={Generative Image Coding with Diffusion Prior},
  author={Chang, Jianhui},
  booktitle={IEEE International Conference on Multimedia and Expo (ICME)},
  year={2025}
}
      </pre>
    </section>
  </main>

  <footer>
    <p>Project page template based on <a href="https://github.com/eliahuhorwitz/Academic-project-page-template">Academic Project Page Template</a></p>
  </footer>
</body>
</html>
